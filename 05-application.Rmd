# Applications

To finalize this manual, we present two guided examples and the script that we developed hoping that this will help in the process of making use of the information present in datos.gob.mx. The first is to illustrate the process of the tidying of the data, and the second is to illustrate the process of extraction and importing a database directly from datos.gob.mx. 

## Tuberculosis Database from World Health Organization

```{r setup, include=FALSE, echo=FALSE}
library(tidyverse)
```


This dataset contains tuberculosis (TB) cases broken down by year, country, age, gender, and diagnosis method. The data comes from the *2014 World Health Organization Global Tuberculosis Report*, available at <http://www.who.int/tb/country/data/download/en/>.

This is a Case Study from the book "R for Data Science" by Hadley Wickham and Garret Grolemund which can be found in <http://r4ds.had.co.nz/tidy-data.html#case-study>. It has been modified and summarised to fit the context of this manual, but the main ideas around are the same.

We are assuming that this dataset has already been imported and has no compatibility problems. Let's first take a look into the raw database in order to gain some insight.

```{r}
who
```

This is a very typical real-life example dataset. It contains redundant columns, odd variable codes, and many missing values. In short, `who` is messy, and we'll need multiple steps to tidy it. 

The first step in our process is to try to guess which information is a variable and which is not. 

* It looks like `country`, `iso2`, and `iso3` are three variables that 
  redundantly specify the country.
  
* `year` is clearly also a variable.

* We don't know what all the other columns are yet, but given the structure 
  in the variable names (e.g. `new_sp_m014`, `new_ep_m014`, `new_ep_f014`) 
  these are likely to be values, not variables.

So we need to gather together all the columns from `new_sp_m014` to `newrel_f65`. We don't know what those values represent yet, so we'll give them the generic name `"key"`. We know the cells represent the count of cases, so we'll use the variable `cases`.

```{r}
who1 <- who %>% 
  gather(new_sp_m014:newrel_f65, key = "key", value = "cases", na.rm = TRUE)
who1
```

Right now we are stuck because we have no clue about what to do with the key column. Although we could actually do things with this database, we will not be able to extract some meaning from it unless we find some information about this entries. This is a very important step because most of the time it is required a dictionary that tells us what does the database mean. A huge majority of the databases found in datos.gob.mx has weird data that can not be parsed. We frequently need to find a file which tells us the meaning of the columns or the data in them, and this add difficulty to the extracting task.

You might be able to parse this out by yourself with a little thought and some experimentation, but luckily we have the data dictionary handy. It tells us:

1.  The first three letters of each column denote whether the column 
    contains new or old cases of TB. In this dataset, each column contains 
    new cases.

1.  The next two letters describe the type of TB:
    
    *   `rel` stands for cases of relapse
    *   `ep` stands for cases of extrapulmonary TB
    *   `sn` stands for cases of pulmonary TB that could not be diagnosed by 
        a pulmonary smear (smear negative)
    *   `sp` stands for cases of pulmonary TB that could be diagnosed be 
        a pulmonary smear (smear positive)

3.  The sixth letter gives the sex of TB patients. The dataset groups 
    cases by males (`m`) and females (`f`).

4.  The remaining numbers gives the age group. The dataset groups cases into 
    seven age groups:
    
    * `014` = 0 -- 14 years old
    * `1524` = 15 -- 24 years old
    * `2534` = 25 -- 34 years old
    * `3544` = 35 -- 44 years old
    * `4554` = 45 -- 54 years old
    * `5564` = 55 -- 64 years old
    * `65` = 65 or older

We need to make a minor fix to the format of the column names: unfortunately the names are slightly inconsistent because instead of `new_rel` we have `newrel` (it's hard to spot this here but if you don't fix it we'll get errors in subsequent steps). 

```{r}
who2 <- who1 %>% 
  mutate(key = stringr::str_replace(key, "newrel", "new_rel"))
who2
```

We can separate the values in each code with two passes of `separate()`. The first pass will split the codes at each underscore.

```{r}
who3 <- who2 %>% 
  separate(key, c("new", "type", "sexage"), sep = "_")
who3
```

Then we might as well drop the `new` column because it's constant in this dataset. While we're dropping columns, let's also drop `iso2` and `iso3` since they're redundant.

```{r}
who3 %>% 
  count(new)
who4 <- who3 %>% 
  select(-new, -iso2, -iso3)
```

Next we'll separate `sexage` into `sex` and `age` by splitting after the first character:

```{r}
who5 <- who4 %>% 
  separate(sexage, c("sex", "age"), sep = 1)
who5
```

This dataset is finally tidy. With this example we were not trying to show the whole details of the tidying process (for which you would be better reading the original source of this material) rather than showing that it is very difficult to actually tidy a dataset. In this case, it requires knowledge about the R language, the tidyverse package and the concept of tidy data. 

This makes it impossible for a non-expert to analyse a raw database, and if the purpose of the open data is that anyone can look into the data and gain information about it, then we have a serious problem. The data found in datos.gob.mx is no exception, and the lack of complete information and organization in the portal does not help to ease this problem.

## The PROSPERA database from datos.gob.mx

This database stores the number of users in each state of Mexico of the PROSPERA social program. The original database can be found in <https://www.prospera.gob.mx/php/Datos%20Abiertos/2_cobertura_atencion_familias/2016/familias_20164.txt>.

Since we are trying to illustrate the steps of importing and extraction, we followed the steps described in the extraction chapter to actually download the file.

### Extraction 

1. We start in the main page of the portal.

`r knitr::include_graphics("screenshots/extraction1.png", dpi = NA)`

2. We type "prospera" in the search bar.

`r knitr::include_graphics("screenshots/extraction2.png", dpi = NA)`

3. We scroll down to find the desired data.

`r knitr::include_graphics("screenshots/extraction3.png", dpi = NA)`

4. We click on the entry title.

`r knitr::include_graphics("screenshots/extraction4.png", dpi = NA)`

5. We click on the title of the first database in this dataset.

`r knitr::include_graphics("screenshots/extraction5.png", dpi = NA)`

6. We download the file from the url and preview it.

`r knitr::include_graphics("screenshots/extraction6.png", dpi = NA)`

`r knitr::include_graphics("screenshots/extraction7.png", dpi = NA)`

We can see that it actually has the structure of a .csv file and it uses the character "|" as separator. We can also see that it does have special characters.

### Importing

```{r }
read_delim("databases/familias_20164.txt", delim = "|")
```

Since we have already identified that the file has the .csv structure, the next step is to have the right encoding.

```{r}
guess_encoding("databases/familias_20164.txt")
```

Now we try to import the file again with the right encoding.

```{r }
read_delim("databases/familias_20164.txt", delim = "|", locale = locale(encoding = "ISO-8859-1"))
```

As we can see, this database is actually very simple and is already tidy. We are very lucky that this database has no column problems or any other issues. This is not a generic case but this examples serves us well to illustrate the usual steps to begin working with a database.

## Scripts

In this section we present the scripts writeen in R that we are using to clean the data.

```{r, eval=FALSE, include=FALSE}
# This script creates an interface to handle the common failures present in the databases that are related to the spanish special characters.
# The first column is the problematic pattern and the second is the replacement (we are trying to replace the problem in such a way that no system has problems importing it)
# To delimit the columns "," is used.
# The entries are ordered alphabetically.
# It is advised to run the whole script to verify that everything worked correctly.

# First we import the library needed
library(tidyverse)

# Now we create a vertical table in whose rows we first put the problematic pattern and next the replacement
erroresTabla <- tribble(
  ~Problema, ~Reemplazo, 
  "\"Pe\"", "Pe", 
  "\"Y\"", "Y", 
  "\"Ye\"", "Ye"
)

# Wow we write this table in a csv file to make use of it later
write_csv(erroresTabla, "scripts/errores.csv")

# Finally, we create a named vector so we can call this script from other scripts
errores <- erroresTabla$Reemplazo
names(errores) <- erroresTabla$Problema
```

```{r, eval=FALSE, include=FALSE}
# First we import the libraries that we are going to use and call the previous script to make use of the "errores" vector
library(stringr)
library(tidyverse)
source("scripts/errores.R")

# Now we create a function that cleans one database at a time
importarProspera <- function(rutaDelArchivo, cabecera, errores){
  # The first step to clean the database is to read ir as a string with the right encoding 
  cadena <- read_file(rutaDelArchivo, locale = locale("es", encoding = "ISO-8859-1")) %>% 
    # Next we call the "errores" vector from the previous script and correct all the pattern that match with the entries of "errores"
    str_replace_all(pattern = errores)
  # The final step  is to read the corrected string as a table with the right heading
  importado <- read_csv(cadena, col_names = cabecera)
}

# We specify the path and headings of the tables that we want to import
prefijo <- "familias_2014"
numeroDeArchivos <- 6
archivos <- str_c("archivos/", prefijo, 1:numeroDeArchivos, ".txt")
archivos
cabecera <- c("claveEstado", 
              "estado", 
              "claveMunicipio", 
              "municipio", 
              "claveLocalidad", 
              "localidad", 
              "claveINEGI", 
              "tipoDeLocalidad", 
              "familiasProspera", 
              "familiasPal", 
              "familiasTotales")
# We create a "list" in which we are going to store the databases
familias2014EnBruto <- vector("list", numeroDeArchivos)
# This line adapts the headings because some databases have less columns
columnas <- list(cabecera, cabecera[c(-7, -8)])
# Now we apply the function created previously to each of the databases in the list 
for(i in seq_along(familias2014EnBruto)){
  if(i %in% 1:4){
    familias2014EnBruto[[i]] <- importarProspera(archivos[i], columnas[[1]], errores)
  }else{
    familias2014EnBruto[[i]] <- importarProspera(archivos[i], columnas[[2]], errores)
  }
}
# Finally we correct the forth database because it has a different column order
familias2014EnBruto[[4]] <- rename(familias2014EnBruto[[4]], claveINEGI = tipoDeLocalidad, tipoDeLocalidad = claveINEGI)
```

